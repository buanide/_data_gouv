{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import sqlglot\n",
    "from sqlglot import exp\n",
    "from sqlglot.optimizer.qualify import qualify\n",
    "from sqlglot.optimizer.scope import find_all_in_scope\n",
    "from sqlglot.optimizer.scope import build_scope\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sqlglot.errors import OptimizeError\n",
    "import os\n",
    "from data_lineage.utils import measure_execution_time\n",
    "from functools import wraps\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#onction pour lire un fichier JSON, afficher son contenu et le stocker dans un dictionnaire\n",
    "def remove_comments(sql):\n",
    "    \"\"\"\n",
    "    Removes line and block comments from an SQL query.\n",
    "\n",
    "    Args:\n",
    "        sql (str): The SQL content to clean.\n",
    "\n",
    "    Returns:\n",
    "        str: The SQL content without comments.\n",
    "    \"\"\"\n",
    "    # Supprime les commentaires de ligne (commençant par -- ou ---)\n",
    "    sql = re.sub(r'--+.*?(\\r\\n|\\r|\\n)', '\\n', sql)\n",
    "    # Supprime les commentaires en bloc /* ... */\n",
    "    sql = re.sub(r'/\\*.*?\\*/', '', sql, flags=re.DOTALL)\n",
    "    return sql\n",
    "\n",
    "def remove_hql_trim(hql_content):\n",
    "    \"\"\"\n",
    "    Removes empty trim() functions from an HQL query.\n",
    "\n",
    "    Args:\n",
    "        hql_content (str): The HQL content to clean.\n",
    "\n",
    "    Returns:\n",
    "        str: The HQL content without empty trim() functions.\n",
    "    \"\"\"\n",
    "    # Supprime les trim() vides\n",
    "    hql_content = re.sub(r'trim\\s*\\(\\s*\\)', \"''\", hql_content, flags=re.IGNORECASE)\n",
    "    return hql_content\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_lineage_dic(hql_file_path: str, results: dict) -> dict:\n",
    "    \"\"\"\n",
    "        Lit une requête HQL depuis un fichier, parse et qualifie la requête, puis construit un dictionnaire\n",
    "        de lignage des données.\n",
    "\n",
    "        Cette fonction analyse une requête HQL pour extraire les informations de lignage des données, telles que\n",
    "        les colonnes détectées, les fonctions d'agrégation, les opérations arithmétiques, la formule SQL et les\n",
    "        tables utilisées. Le résultat est structuré sous la forme d'un dictionnaire.\n",
    "\n",
    "        Args:\n",
    "            hql_file_path (str): Le chemin du fichier HQL à analyser.\n",
    "            results (dict): Dictionnaire contenant des résultats intermédiaires pour l'analyse, issu de la fonction 'process_hql_files' \n",
    "\n",
    "        Returns:\n",
    "            dict: Dictionnaire des lignages où chaque clé est un fichier HQL et chaque valeur est un dictionnaire\n",
    "                contenant les informations de lignage des données. La structure est la suivante :\n",
    "                {\n",
    "                    \"<chemin_fichier>.hql\": {\n",
    "                        \"ALIAS_OR_NAME\": {\n",
    "                            \"Alias/Projection\": ...,\n",
    "                            \"Colonnes détectées\": [...],\n",
    "                            \"Fonctions d'agg\": [...],\n",
    "                            \"Opérations arithmétiques\": [...],\n",
    "                            \"Formule SQL\": ...,\n",
    "                            \"Table(s) utilisées\": ...\n",
    "                        },\n",
    "                        ...\n",
    "                    },\n",
    "                    ...\n",
    "                }\n",
    "        \"\"\"\n",
    "    lineage_dict = {}\n",
    "    temp_projection=0\n",
    "\n",
    "    try:\n",
    "        with open(hql_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            hql_content = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Fichier introuvable: {hql_file_path}\")\n",
    "        return {}\n",
    "    \n",
    "    hql_content=remove_comments(hql_content)\n",
    "    hql_content=remove_hql_trim(hql_content)\n",
    "    expression = sqlglot.parse_one(hql_content, read=\"hive\")\n",
    "    if not expression:\n",
    "        print(f\"Impossible de parser le HQL dans: {hql_file_path}\")\n",
    "        return {}\n",
    "    \n",
    "    try:\n",
    "        expression_qualified= qualify(expression)\n",
    "    except sqlglot.errors.OptimizeError as e:\n",
    "        print(f\"Warning: {e}\")  # Affiche un avertissement sans interrompre l'exécution\n",
    "        expression_qualified = expression  \n",
    "    all_selects = list(expression_qualified.find_all(exp.Select))\n",
    "    print(\"file_path\",hql_file_path)\n",
    "    lineage_dict[hql_file_path] = {}\n",
    "    for select_expr in all_selects:\n",
    "        tables_in_select,_ = measure_execution_time(find_tables_in_select,select_expr)\n",
    "        # print(\"tablein select\",tables_in_select)\n",
    "        tables_str = \", \".join(tables_in_select) if tables_in_select else \"Aucune table\"\n",
    "        for proj in select_expr.selects:\n",
    "            if isinstance(proj, exp.Alias):\n",
    "                alias_name = proj.alias or \"NO_ALIAS\"\n",
    "                expr_to_analyze = proj.this\n",
    "                # print(\"expr to analyze\",expr_to_analyze)\n",
    "                # print(repr(proj))\n",
    "\n",
    "            else:\n",
    "                alias_name = proj.alias_or_name or \"NO_ALIAS\"\n",
    "                expr_to_analyze = proj\n",
    "            \n",
    "            #print(\"expr to analyze\",expr_to_analyze)\n",
    "            info,t = measure_execution_time(analyze_projection,expr_to_analyze, hql_content, results)\n",
    "            temp_projection+=t\n",
    "\n",
    "            lineage_dict[hql_file_path][alias_name] = {\n",
    "                \"Alias/Projection\": alias_name,\n",
    "                \"Colonnes détectées\": info[\"columns_used\"],\n",
    "                # \"Schema\": schemas_par_col,\n",
    "                \"agg\": info[\"aggregations\"],\n",
    "                \"Opérations arithmétiques\": info[\"arithmetic_ops\"],\n",
    "                \"Formule SQL\": info[\"formula_sql\"],\n",
    "                \"Table(s) utilisées\": tables_str,\n",
    "            }\n",
    "    print(\"analyse des champs\",temp_projection)\n",
    "    #print(\"lineage_dict\",lineage_dict)\n",
    "    return lineage_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_lineage(dependencies, results):\n",
    "    \"\"\"\n",
    "    Construit le lignage des tables Hive à partir des fichiers HQL.\n",
    "\n",
    "    Args:\n",
    "        dependencies (dict): Dictionnaire des dépendances où chaque clé est une table Hive\n",
    "                             et chaque valeur est une liste de fichiers HQL associés.\n",
    "        results (dict): Dictionnaire contenant des résultats intermédiaires pouvant être utilisés\n",
    "                        par la fonction `create_lineage_dic`.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionnaire des lignages où chaque clé est un fichier HQL et chaque valeur est\n",
    "              le résultat de l'analyse par `create_lineage_dic`.\n",
    "    \"\"\"\n",
    "    lineage = {}\n",
    "    for hive_table, hql_files in dependencies.items():\n",
    "        if hive_table!=None:\n",
    "\n",
    "            if isinstance(hql_files, str):  # Gérer le cas où un seul fichier est donné sous forme de chaîne\n",
    "                hql_files = [hql_files] \n",
    "            if hql_files!=None:       \n",
    "                for hql_file in hql_files:\n",
    "                    if not hql_file.startswith(\"/\"):\n",
    "                        if os.path.exists(hql_file):  # Vérifie que le fichier existe\n",
    "                            current_lineage_dict=create_lineage_dic(hql_file, results)\n",
    "                            #print(\"current_lineage_dict\",current_lineage_dict)\n",
    "                            lineage[hql_file] = current_lineage_dict\n",
    "                            #print(\"lineage\",lineage)\n",
    "                        else:\n",
    "                            print(f\"Fichier HQL non trouvé : {hql_file}\")\n",
    "            else:\n",
    "                pass\n",
    "    return lineage\n",
    "\n",
    "\n",
    "def read_json(input_file):\n",
    "    try:\n",
    "        # Lecture et chargement du fichier JSON\n",
    "        with open(input_file, \"r\", encoding=\"utf-8\") as infile:\n",
    "            data = json.load(infile)\n",
    "\n",
    "        # Affichage du contenu du fichier JSON\n",
    "        # Retourner le contenu du fichier JSON sous forme de dictionnaire\n",
    "        return data\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Erreur lors du chargement du fichier JSON : {e}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Le fichier '{input_file}' est introuvable.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Une erreur est survenue : {e}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "\n",
    "def track_fields_across_lineage(rdms_table_name,data, results,dic_fields_from_dwh):\n",
    "    \"\"\"\n",
    "    Suit les opérations menés sur les colonnes de la première à la dernière table pour chaque ligne de dépendances  pour une table rdms\n",
    "\n",
    "    Args:\n",
    "        data (dict): Dictionnaire contenant plusieurs tables RDMS et leurs informations :\n",
    "                     - \"liste_champs\" : Liste des champs à suivre\n",
    "                     - \"dependencies\" : Dictionnaire des tables Hive et leurs fichiers HQL associés\n",
    "        results (dict): Dictionnaire contenant des résultats intermédiaires pour l'analyse.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionnaire contenant le lignage des champs sous la forme :\n",
    "              {\n",
    "                  \"champ1\": [\n",
    "                      { \"chemin_du_fichier.hql\": \"path/alors/exec.hql\",\n",
    "                        \"Opérations arithmétiques\": [\"+\", \"-\", ...],\n",
    "                        \"Formule SQL\": \"SELECT ... FROM ... WHERE ...\",\n",
    "                        \"Table(s) utilisées\": [\"table1\", \"table2\"]},\n",
    "                      { ... }\n",
    "                  ],\n",
    "                  \"champ2\": [ ... ]\n",
    "              }\n",
    "    \"\"\"\n",
    "    overall_field_tracking = {}\n",
    "    # parcours du dictionnaire contenant le sinfos des tables rdms\n",
    "\n",
    "\n",
    "    for i, info in data.items():\n",
    "        fields_first_hive_table = info.get(\"liste_champs\", [])\n",
    "        rdms=info.get('rdms_table')\n",
    "        tmp_dwh=info.get('staging_table_dwh',None)\n",
    "        first_hive_table=info.get('first_hive table')\n",
    "        #print('rmds_table',rdms)\n",
    "        fields_rdms_tmp=None\n",
    "        \n",
    "        #print(\"rdms_table_name\",rdms_table_name)\n",
    "        if rdms.lower()==rdms_table_name.lower():\n",
    "            # on extrait les dependences du datalake des tables rdms\n",
    "            dependencies = info.get(\"dependencies\",None)\n",
    "            lineage = build_lineage(dependencies, results)  # Extraction du dictionnaire de lineag epour cette table\n",
    "            # pour chaque fichier hql correspondant à l'alimentation d'une table on a besoin des informations sur chacun des champs de cette table sous forme d'un dictionnaire\n",
    "            #print(\"lineage\",lineage)\n",
    "            \n",
    "        # Recherche des champs de la table temporaire et rdms finale dans le dictionnaire en paramètre dans le dictionnaire et on récupère ses champs \n",
    "            for i,value in dic_fields_from_dwh.items():\n",
    "                    if i.lower()==tmp_dwh.lower():\n",
    "                        fields_rdms_tmp=value\n",
    "                        #print(\"rdms_temp_fields\",fields_rdms_tmp)\n",
    "\n",
    "                    if i.lower()==rdms.lower():\n",
    "                        fields_rdms=value\n",
    "\n",
    "                    if fields_rdms_tmp!=None and fields_rdms!=None:\n",
    "                        break\n",
    "\n",
    "            if fields_rdms_tmp!=None:\n",
    "                    # \n",
    "                    for hql_file, tables in lineage.items():\n",
    "                        for table, details in tables.items():\n",
    "                            for key, info in details.items():\n",
    "                                detected_column = info.get(\"Colonnes détectées\",None)\n",
    "                                if not detected_column:  # Si aucune colonne détectée\n",
    "                                    detected_column = \"NO DETECTED COLUMN\"\n",
    "                                    if not detected_column:\n",
    "                                        detected_column = \"INCONNUE\"\n",
    "                                # Si c'est une liste, on la met en minuscule\n",
    "                                if isinstance(detected_column, list):\n",
    "                                    detected_column = [col.lower() for col in detected_column]\n",
    "                                else:\n",
    "                                    detected_column = detected_column.lower()\n",
    "                                for col in detected_column if isinstance(detected_column, list) else [detected_column]:\n",
    "                                    if col not in overall_field_tracking:\n",
    "                                        overall_field_tracking[col] = []\n",
    "                                    # on a besoin de connaitre à quel champ de la table temporaire au dwh correspond le champ de la table du datalake\n",
    "                                    alias=info.get(\"Alias/Projection\", None)\n",
    "                                    alias_upper=alias.upper()\n",
    "                                    #print(\"fields_rdms_tmp\",fields_rdms_tmp)\n",
    "                                    previous_entry = None\n",
    "                                    if alias!=None:\n",
    "                                        # on regarde si l'alias est dans la liste des champs des champs\n",
    "                                        #  de dernière table d'aggrégation avant l'insertion dans la table rdms     \n",
    "                                        if  alias_upper in fields_rdms_tmp:\n",
    "                                            try:    \n",
    "                                               # on se rassure que les deux listes de champs ont la même taille \n",
    "                                              \n",
    "                                                if len(fields_rdms_tmp)==len(fields_rdms):\n",
    "                                                     #print(\"same size\")\n",
    "                                                     indice = fields_rdms_tmp.index(alias_upper)  # 25 n'est pas dans la liste\n",
    "                                                     rdms_field=fields_rdms[indice]\n",
    "                                                     #print(\"rdms_field\",rdms_field)\n",
    "                                                     #print(\"alias\",alias)\n",
    "                                                     field_entry = {\n",
    "                                                        \"rdms_field\":rdms_field,\n",
    "                                                        \"path\": \"\",\n",
    "                                                        \"colonne\": \"\",\n",
    "                                                        \"Opérations arithmétiques\": \"\",\n",
    "                                                        \"Alias\": alias,\n",
    "                                                        \"Formule SQL\": \"\",\n",
    "                                                        \"Table(s) utilisées\": \"\"\n",
    "                                                    }\n",
    "                                                     overall_field_tracking[col].append(field_entry)\n",
    "                                            except ValueError:\n",
    "                                                print(\"L'alias n'est pas dans la liste des champs de la table\")\n",
    "                                        \n",
    "                                        formule=info.get(\"Formule SQL\", \"\")\n",
    "                                        if col in formule:\n",
    "                                            if rdms_field!=None:\n",
    "                                                field_entry = {\n",
    "                                                    \"rdms_field\":rdms_field,\n",
    "                                                    \"path\": hql_file,\n",
    "                                                    \"colonne\": col,\n",
    "                                                    \"Opérations arithmétiques\": info.get(\"Opérations arithmétiques\", []),\n",
    "                                                    \"Alias\": info.get(\"Alias/Projection\", None),\n",
    "                                                    \"Formule SQL\": info.get(\"Formule SQL\", \"\"),\n",
    "                                                    \"Table(s) utilisées\": info.get(\"Table(s) utilisées\", \"\")\n",
    "                                                }\n",
    "                                            else:\n",
    "                                                field_entry = {\n",
    "                                                    \"rdms_field\":\"\",\n",
    "                                                    \"path\": hql_file,\n",
    "                                                    \"colonne\": col,\n",
    "                                                    \"Opérations arithmétiques\": info.get(\"Opérations arithmétiques\", []),\n",
    "                                                    \"Alias\": info.get(\"Alias/Projection\", None),\n",
    "                                                    \"Formule SQL\": info.get(\"Formule SQL\", \"\"),\n",
    "                                                    \"Table(s) utilisées\": info.get(\"Table(s) utilisées\", \"\")\n",
    "                                                }\n",
    "\n",
    "                                    overall_field_tracking[col].append(field_entry)\n",
    "    return overall_field_tracking\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def list_all_files(directory: str) -> list:\n",
    "    \"\"\"\n",
    "    Retourne tous les chemins de fichiers dans un répertoire, y compris les sous-répertoires.\n",
    "    \"\"\"\n",
    "    file_paths = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_paths.append(os.path.join(root, file))\n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlglot\n",
    "import os\n",
    "from sqlglot import exp\n",
    "from sqlglot import parse_one\n",
    "from sqlglot.optimizer.scope import find_all_in_scope\n",
    "from sqlglot.optimizer.scope import build_scope\n",
    "from sqlglot.lineage import lineage\n",
    "import re\n",
    "from sqlglot import exp\n",
    "from sqlglot.optimizer.qualify import qualify\n",
    "from data_lineage.utils import list_all_files\n",
    "from data_lineage.fields import process_hql_files\n",
    "from data_lineage.fields import extract_lineage_fields\n",
    "from data_lineage.fields import export_lineage_to_excel\n",
    "from data_lineage.fields import create_lineage_dic\n",
    "from data_lineage.fields import print_lineage_dict\n",
    "from data_lineage.utils import map_rdms_file_hql_file\n",
    "from data_lineage.utils import extract_hive_table_and_queries\n",
    "from data_lineage.fields import get_unique_tables_names_from_lineage_dict\n",
    "from data_lineage.utils import extract_exec_queries\n",
    "from data_lineage.utils import generate_dic_with_rdms_and_dependencies\n",
    "from data_lineage.fields import get_hql_path_from_table_name\n",
    "from data_lineage.utils import process_conf_files\n",
    "from data_lineage.utils import get_dir_dependances_2\n",
    "from data_lineage.fields import create_dict_tables_dependencies_and_path\n",
    "from data_lineage.fields import create_dict_tables_dependencies_and_path_for_hive_tables\n",
    "from data_lineage.fields import build_lineage\n",
    "from data_lineage.fields import track_fields_across_lineage\n",
    "from data_lineage.fields import track_fields_across_lineage_for_data_lake\n",
    "import time\n",
    "from data_lineage.utils import measure_execution_time\n",
    "from data_lineage.fields import export_tracking_lineage_to_excel\n",
    "from data_lineage.utils import display_table_dependencies_2\n",
    "from data_lineage.format_json import read_json\n",
    "from data_lineage.data_sources import data_sources_lineage\n",
    "from data_lineage.fields import export_tracking_lineage_to_excel_2\n",
    "\n",
    "# Démarrer le chronomètre\n",
    "path=r\"C:\\\\Users\\\\YBQB7360\\\\Downloads\\\\HDFS\\\\HDFS\\\\PROD\\\\SCRIPTS\\\\FT\\\\BDI\\\\FT_BDI_AMELIORE\\\\insert_into_spark_ft_bdi_ameliore.hql\"\n",
    "name_file=os.path.basename(path)\n",
    "hdfs_dir = r\"C:\\Users\\YBQB7360\\Downloads\\HDFS\\HDFS\"\n",
    "paths_scripts=r'C:\\Users\\YBQB7360\\Downloads\\HDFS\\HDFS\\PROD\\SCRIPTS'\n",
    "file_scripts_paths=list_all_files(paths_scripts)\n",
    "create_table_dic=process_hql_files(file_scripts_paths)\n",
    "#dic_table_fields=extract_lineage_fields(hql_content)\n",
    "directory_conf = r\"C:\\Users\\YBQB7360\\Downloads\\HDFS\\HDFS\\PROD\\CONF\"\n",
    "table_name='MON.FT_A_DATA_TRANSFER'\n",
    "flow_file_path=r\"C:\\Users\\YBQB7360\\Documents\\Data gouvernance\\PRODv2.0\\PRODv2.0.json\"\n",
    "#liste_table=list(dic_table_fields.keys())\n",
    "#lineage_dic,_ = measure_execution_time(create_lineage_dic, path, create_table_dic)\n",
    "#export_lineage_to_excel(lineage_dic, \"lineage_\"+name_file+\".xlsx\")\n",
    "dict_fields_from_dwh=read_json(r\"C:\\Users\\YBQB7360\\Documents\\Data gouvernance\\_data_gouv\\tables_mon_fields_description_dict.json\")\n",
    "\n",
    "dic_rdms_hive=extract_hive_table_and_queries(directory_conf)\n",
    "dict_table_paths=map_rdms_file_hql_file(dic_rdms_hive,file_scripts_paths)\n",
    "dic_files_queries_paths = process_conf_files(directory_conf, hdfs_dir)\n",
    "\n",
    "#  dic table hive -> dependances\n",
    "dic_tables_dependencies = get_dir_dependances_2(dic_files_queries_paths)\n",
    "#display_table_dependencies_2(dic_tables_dependencies,\"MON.SPARK_SMS_PARC\")\n",
    "dic_rdms_hive_dependencies=generate_dic_with_rdms_and_dependencies(dic_rdms_hive, dic_tables_dependencies)\n",
    "# permet de ratacher à chaque source de données le ou les noms des hql qui l'alimente\n",
    "dict_tables_dependencies_and_fields,_=measure_execution_time(create_dict_tables_dependencies_and_path,dict_table_paths,dic_rdms_hive_dependencies,create_table_dic,dic_files_queries_paths)\n",
    "\n",
    "filter_list=[\"MON.FT_GLOBAL_ACTIVITY\"]\n",
    "#data_sources_lineage(hdfs_dir,paths_scripts,directory_conf,flow_file_path,filter_list,\"dependencies_with_raw_server_filtered.xlsx\")  \n",
    "#dict_tables_hive,_=measure_execution_time(create_dict_tables_dependencies_and_path_for_hive_tables,dict_table_paths,dic_tables_dependencies,create_table_dic)\n",
    "\"\"\"\n",
    "print(\"dict_tables_dependencies_and_fields\")\n",
    "\n",
    "for i,value in dict_tables_dependencies_and_fields.items():\n",
    "    print(\"rdms_table\",value.get('rdms_table',None))\n",
    "    print(\"first_hive table\",value.get('first_hive table',None))\n",
    "    dependencies=value.get('dependencies',None)\n",
    "    print(dependencies)\n",
    "    break\n",
    "\n",
    "print(\"dict_tables_hive\")\n",
    "for i,value in dict_tables_hive.items():\n",
    "    print(\"i\",i,\"value\",value)\n",
    "    break\n",
    "\"\"\"\n",
    "#lineage_dic_for_one_chain_of_dependencies,t=measure_execution_time(build_lineage,dependencies,create_table_dic)\n",
    "\n",
    "#lineage_fields_across_dependencies,t=measure_execution_time(track_fields_across_lineage_for_data_lake,table_name,dict_tables_dependencies_and_fields,create_table_dic,dict_tables_hive)\n",
    "lineage_fields_across_dependencies,t=measure_execution_time(track_fields_across_lineage,table_name,dict_tables_dependencies_and_fields,create_table_dic,dict_fields_from_dwh)\n",
    "\n",
    "#print(\"lineage_fields_across_dependencies\",lineage_fields_across_dependencies)\n",
    "#export_tracking_lineage_to_excel(lineage_fields_across_dependencies,\"lineage_\"+table_name+\".xlsx\")\n",
    "export_tracking_lineage_to_excel_2(lineage_fields_across_dependencies,\"lineage_\"+table_name+\".xlsx\")\n",
    "#dict_tables_hql_from_request_lineage=get_hql_path_from_table_name(dict_table_paths,list_table_from_hql)\n",
    "#print(dict_tables_hql_from_request_lineage)\n",
    "#nom=\"MON.FT_CONTRACT_SNAPSHOT\"\n",
    "#for i,value in dict_table_paths.items():\n",
    "    #contrat=dict_table_paths.get(nom,None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
